#extension GL_GOOGLE_include_directive: require
#extension GL_EXT_ray_tracing: require
#extension GL_EXT_control_flow_attributes: require
#extension GL_EXT_shader_16bit_storage: require
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#extension GL_EXT_shader_explicit_arithmetic_types_int16: require
#extension GL_EXT_shader_explicit_arithmetic_types_int64: require
#extension GL_EXT_buffer_reference: require

#ifdef REORDER_INVOCATIONS
#extension GL_NV_shader_invocation_reorder: require
// For hit shader invocation reordering hint
#extension GL_EXT_buffer_reference: require
#extension GL_EXT_buffer_reference_uvec2: require
#endif

#include "aovs.glsl"

#if (AOV_MASK & AOV_BIT_DEBUG_CLOCK_CYCLES) != 0
#extension GL_EXT_shader_explicit_arithmetic_types_int64: require
#extension GL_ARB_shader_clock: require
#endif

#include "rp_main_payload.glsl"
#include "rp_main_descriptors.glsl"
#include "colormap.glsl"

layout(location = PAYLOAD_INDEX_SHADE) rayPayloadEXT ShadeRayPayload rayPayload;
layout(location = PAYLOAD_INDEX_SHADOW) rayPayloadEXT ShadowRayPayload shadowRayPayload;

#ifdef REORDER_INVOCATIONS
layout(buffer_reference, hitobjectshaderrecordnv) buffer ShaderRecordBuffer
{
    uint closestHitShaderIndex;
    uint anyHitShaderIndex;
};
#endif

//
// This path tracing implementation was initially based on the MDL SDK DXR sample:
// https://github.com/NVIDIA/MDL-SDK/tree/master/examples/mdl_sdk/dxr
// but has since then received many changes such as flattened ray tracing calls.
//
// The volume path tracing part is partly based on the Optix 7 example renderer:
// https://github.com/NVIDIA/OptiX_Apps/tree/master/apps/MDL_renderer
//

#if MEDIUM_STACK_SIZE > 0
float sampleDistance(vec3 albedo, vec3 throughput, vec3 sigma_t, float xi, out vec3 pdf)
{
    vec3 weights = throughput * albedo;

    float sum = weights.x + weights.y + weights.z;

    pdf = (sum > 1e-9) ? (weights / sum) : vec3(1.0 / 3.0);

    if (xi < pdf.x)
    {
        return sigma_t.x;
    }
    else if (xi < (pdf.x + pdf.y))
    {
        return sigma_t.y;
    }
    else
    {
        return sigma_t.z;
    }
}

// cmp. d'Eon: "A Hitchhiker's Guide to Multiple Scattering"
float sampleHenyeyGreensteinCos(float r, float g)
{
    if (abs(g) < 1e-3f)
    {
        return 1.0 - 2.0 * r; // isotropic medium
    }

    float s = (1.0 - g * g) / (1.0 - g + 2.0 * g * r);

    return (1.0 + g * g - s * s) / (2.0 * g);
}

void sampleVolumeScatteringDirection(vec2 xi, float bias, inout vec3 dir)
{
    float cos_theta = sampleHenyeyGreensteinCos(xi.x, bias);

    float sin_theta = sqrt(max(0.0, 1.0 - cos_theta * cos_theta));

    float phi = 2.0 * PI * xi.y;

    vec3 t, b;
    orthonormal_basis(dir, t, b);

    dir = t * sin_theta * cos(phi) + b * sin_theta * sin(phi) + dir * cos_theta;
}
#endif

bool russian_roulette(in float random_float, inout vec3 throughput)
{
    float max_throughput = max(throughput.r, max(throughput.g, throughput.b));
    float p = min(max_throughput, ubo.rrInvMinTermProb);

    if (random_float > p)
    {
        return true;
    }

    throughput /= p;

    return false;
}

// Filter Importance Sampling of a Gauss kernel
// https://ieeexplore.ieee.org/document/4061554
// We use the Box-Muller transform to draw samples from the distribution.
// Also see: https://nvpro-samples.github.io/vk_mini_path_tracer/extras.html#gaussianfilterantialiasing
vec2 fisGauss(vec2 xi)
{
    float u1 = max(1e-38, xi.x); // needs to be in (0, 1]
    float u2 = xi.y; // in [0, 1]

    // https://academo.org/demos/gaussian-distribution/
    float sigma = 0.375; // NV tutorial and Cycles

    float r = sigma * sqrt(-2.0 * log(u1));
    float phi = 2.0 * PI * u2;

    return vec2(cos(phi), sin(phi)) * r;
}

void clearAovs(uint pixelIndex)
{
#if (AOV_MASK & AOV_BIT_DEBUG_BARYCENTRICS) != 0
    BarycentricsAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_BARYCENTRICS].rgb;
#endif
#if (AOV_MASK & AOV_BIT_DEBUG_TEXCOORDS) != 0
    TexcoordsAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_TEXCOORDS].rgb;
#endif
#if (AOV_MASK & AOV_BIT_DEBUG_OPACITY) != 0
    OpacityAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_OPACITY].rgb;
#endif
#if (AOV_MASK & AOV_BIT_DEBUG_TANGENTS) != 0
    TangentsAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_TANGENTS].rgb;
#endif
#if (AOV_MASK & AOV_BIT_DEBUG_BITANGENTS) != 0
    BitangentsAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_BITANGENTS].rgb;
#endif
#if (AOV_MASK & AOV_BIT_DEBUG_THIN_WALLED) != 0
    ThinWalledAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_THIN_WALLED].rgb;
#endif
#if (AOV_MASK & AOV_BIT_OBJECT_ID) != 0
    ObjectIdAov[pixelIndex] = ClearValuesI[AOV_ID_OBJECT_ID].x;
#endif
#if (AOV_MASK & AOV_BIT_DEPTH) != 0
    DepthAov[pixelIndex] = ClearValuesF[AOV_ID_DEPTH].x;
#endif
#if (AOV_MASK & AOV_BIT_FACE_ID) != 0
    FaceIdAov[pixelIndex] = ClearValuesI[AOV_ID_FACE_ID].x;
#endif
#if (AOV_MASK & AOV_BIT_INSTANCE_ID) != 0
    InstanceIdAov[pixelIndex] = ClearValuesI[AOV_ID_INSTANCE_ID].x;
#endif
#if (AOV_MASK & AOV_BIT_DEBUG_DOUBLE_SIDED) != 0
    DoubleSidedAov[pixelIndex] = ClearValuesF[AOV_ID_DEBUG_DOUBLE_SIDED].rgb;
#endif

    // AOVs that converge over time.
    if (ubo.sampleOffset != 0)
    {
        return;
    }

#if (AOV_MASK & AOV_BIT_COLOR) != 0
    ColorAov[pixelIndex] = ClearValuesF[AOV_ID_COLOR];
#endif
#if (AOV_MASK & AOV_BIT_NORMAL) != 0
    NormalsAov[pixelIndex] = ClearValuesF[AOV_ID_NORMAL].rgb;
#endif
}

void main()
{
#if (AOV_MASK & AOV_BIT_DEBUG_CLOCK_CYCLES) != 0
    uint64_t start_cycle_count = clockARB();
#endif

    uvec2 pixel_pos = gl_LaunchIDEXT.xy;
    uint imageWidth = ubo.imageDims & 0xFFFFu;
    uint imageHeight = ubo.imageDims >> 16;

    uint pixelIndex = pixel_pos.x + pixel_pos.y * imageWidth;

    clearAovs(pixelIndex);

    vec3 camera_right = cross(ubo.cameraForward, ubo.cameraUp);
    float aspect_ratio = float(imageWidth) / float(imageHeight);

    float H = 1.0;
    float W = H * aspect_ratio;
    float d = H / (2.0 * tan(ubo.cameraVFoV * 0.5));

    float WX = W / float(imageWidth);
    float HY = H / float(imageHeight);

    vec3 C = ubo.cameraPosition + ubo.cameraForward * d;
    vec3 L = C - camera_right * W * 0.5 - ubo.cameraUp * H * 0.5;

    float invSpp = 1.0 / float(ubo.spp);

    vec3 pixel_color = vec3(0.0, 0.0, 0.0);
    for (uint s = 0; s < ubo.spp; ++s)
    {
        uint sampleIndex = ubo.sampleOffset + s;
#ifdef RAND_4D
        uvec4 rng_state = rng4d_init(pixel_pos.xy, sampleIndex);
        vec4 rand4 = rng4d_next4f(rng_state);
        vec2 rand2_xy = rand4.xy;
#else
        uint rng_state = rng1d_init(pixelIndex, sampleIndex);
        vec2 rand2_xy = rng1d_next2f(rng_state);
#endif

        vec2 sampleOffset = vec2(0.5);

#ifdef JITTERED_SAMPLING
#ifdef FILTER_IMPORTANCE_SAMPLING
        // Importance sample multi-pixel filtering kernel
        sampleOffset = vec2(0.5) + fisGauss(rand2_xy);
#else
        // Uniform pixel area sampling
        sampleOffset = rand2_xy;
#endif
#endif

        vec3 P =
            L +
            (float(pixel_pos.x) + sampleOffset.x) * camera_right * WX +
            (float(pixel_pos.y) + sampleOffset.y) * ubo.cameraUp * HY;

        vec3 ray_origin = ubo.cameraPosition;
        vec3 ray_dir = normalize(P - ray_origin);

        // Depth of Field
        // (cmp. RT Gems II; Boksansky's Reference PT)

#ifdef DEPTH_OF_FIELD
        if (ubo.lensRadius > 0.0)
        {
#ifdef RAND_4D
            vec2 rand2_zw = rand4.zw;
#else
            vec2 rand2_zw = rng1d_next2f(rng_state);
#endif

            vec3 focalPoint = ray_origin + ray_dir * ubo.focusDistance;
            vec2 apertureSample = sample_hemisphere(rand2_zw).xy * ubo.lensRadius;

            ray_origin += apertureSample.x * camera_right;
            ray_origin += apertureSample.y * ubo.cameraUp;

            ray_dir = normalize(focalPoint - ray_origin);
        }
#endif

        /* Beware: a single direction component must not be zero,
         * because we often take the inverse of the direction. */
        ray_dir += vec3(equal(ray_dir, vec3(0.0))) * FLOAT_MIN;

        /* Path trace sample and accumulate color. */
        rayPayload.throughput     = vec3(1.0);
        rayPayload.bitfield       = 0;
        rayPayload.radiance       = vec3(0.0);
        rayPayload.rng_state      = rng_state;
        rayPayload.ray_origin     = ray_origin;
        rayPayload.ray_dir        = ray_dir;
#if MEDIUM_STACK_SIZE > 0
        rayPayload.walkSegmentPdf = vec3(1.0);
#endif
        rayPayload.pixelIndex     = pixelIndex;

        // Correct clip plane curving by getting the hypothenuse length (our current ray)
        // from the adjacent edge (the forward vector) the angle between both.
        float cosConeAngle = max(1e-5, dot(ray_dir, ubo.cameraForward));
        vec2 clipRange = unpackHalf2x16(ubo.clipRangePacked) / cosConeAngle;

        // Path trace
        uint rrBounceOffset = ubo.maxBouncesAndRrBounceOffset & 0xFFFFu;
        uint maxBounces = min(SHADE_RAY_PAYLOAD_BOUNCES_MASK, ubo.maxBouncesAndRrBounceOffset >> 16);

        [[loop]]
        while (true)
        {
            // Loop exit.
            uint bounce = (rayPayload.bitfield & SHADE_RAY_PAYLOAD_BOUNCES_MASK);
            bool terminate = (rayPayload.bitfield & SHADE_RAY_PAYLOAD_TERMINATE_FLAG) != 0;

            if (bounce >= maxBounces || terminate)
            {
                 break;
            }

            float tMin = 0.0;
            float tMax = FLOAT_MAX;
#ifdef CLIPPING_PLANES
            if (bounce == 0)
            {
              tMin = clipRange.x;
              tMax = clipRange.y;
            }
#endif

            // Calculate distance for volume sampling
#if MEDIUM_STACK_SIZE > 0
            uint mediumIdx = shadeRayPayloadGetMediumIdx(rayPayload);

            if (mediumIdx > 0)
            {
                Medium m = rayPayload.media[mediumIdx - 1];

                rayPayload.walkSegmentPdf = vec3(1.0);

                uint walkLength = shadeRayPayloadGetWalk(rayPayload);
                bool hasScattering = any(greaterThan(m.sigma_s, vec3(0.0)));

                if (hasScattering && walkLength <= ubo.maxVolumeWalkLength)
                {
                    vec3 albedo = safe_div(m.sigma_s, m.sigma_t);

#ifdef RAND_4D
                    vec2 xi = rng4d_next4f(rayPayload.rng_state).xy;
#else
                    vec2 xi = rng1d_next2f(rayPayload.rng_state);
#endif

                    float s = sampleDistance(albedo, rayPayload.throughput, m.sigma_t, xi.x, rayPayload.walkSegmentPdf);

                    s *= ubo.metersPerSceneUnit;

                    tMax = -log(1.0 - xi.y) / s; // collision free distance (mean free path)
                }
            }
#endif

            // Closest hit shading
            rayPayload.neeContrib = vec3(0.0);

#ifdef REORDER_INVOCATIONS
            hitObjectNV hitObject;

            hitObjectTraceRayNV(
                hitObject,             // hit object
                sceneAS,               // top-level AS
                0,                     // ray flags
                0xFF,                  // cull mask
                0,                     // sbt record offset
                2,                     // sbt record stride
                0,                     // miss index
                rayPayload.ray_origin, // ray origin
                tMin,                  // ray min range
                rayPayload.ray_dir,    // ray direction
                tMax,                  // ray max range
                PAYLOAD_INDEX_SHADE    // payload
            );

            uint reorderHint = 0xFFFFFFFFu;

            if (hitObjectIsHitNV(hitObject))
            {
                uvec2 handle = hitObjectGetShaderRecordBufferHandleNV(hitObject);
                reorderHint = ShaderRecordBuffer(handle).closestHitShaderIndex;
            }

            reorderThreadNV(hitObject, reorderHint, REORDER_HINT_BIT_COUNT);

            hitObjectExecuteShaderNV(hitObject, PAYLOAD_INDEX_SHADE);
#else
            traceRayEXT(
                sceneAS,               // top-level AS
                0,                     // ray flags
                0xFF,                  // cull mask
                0,                     // sbt record offset
                2,                     // sbt record stride
                0,                     // miss index
                rayPayload.ray_origin, // ray origin
                tMin,                  // ray min range
                rayPayload.ray_dir,    // ray direction
                tMax,                  // ray max range
                PAYLOAD_INDEX_SHADE    // payload
            );
#endif

            // NEE contribution
#ifdef NEXT_EVENT_ESTIMATION
            {
                shadowRayPayload.rng_state = rayPayload.rng_state;
                shadowRayPayload.shadowed = true; // Gets set to false by miss shader

                vec3 shadowray_origin = rayPayload.ray_origin; // actually not correct, but we compensate with tMin
                float lightDist = length(rayPayload.neeToLight);
                vec3 shadowray_dir = safe_div(rayPayload.neeToLight, lightDist); // according to spec, must not contain NaNs

                // NV best practices recommends unconditional dispatch with tMin = tMax = 0.0
                bool traceRay = luminance(rayPayload.neeContrib) > 1e-6 && lightDist > 1e-9;
                uint rayFlags = gl_RayFlagsTerminateOnFirstHitEXT | gl_RayFlagsSkipClosestHitShaderEXT;
                float tMin = traceRay ? 0.01 : 0.0; // FIXME: investigate resulting artifacts
                float tMax = traceRay ? lightDist : 0.0;

                traceRayEXT(
                    sceneAS,             // top-level acceleration structure
                    rayFlags,            // rayFlags
                    0xFF,                // cullMask
                    1,                   // sbtRecordOffset (shadow test: use second hit group)
                    2,                   // sbtRecordStride
                    1,                   // missIndex (differs because of shadow test)
                    shadowray_origin,    // ray origin
                    tMin,                // ray min range
                    shadowray_dir,       // ray direction
                    tMax,                // ray max range
                    PAYLOAD_INDEX_SHADOW // payload
                );

                bool addContrib = traceRay && !shadowRayPayload.shadowed;

                rayPayload.rng_state = shadowRayPayload.rng_state;
                rayPayload.radiance += rayPayload.neeContrib * float(addContrib);

#if (AOV_MASK & AOV_BIT_DEBUG_NEE) != 0
                if (bounce == 0)
                {
                    NeeAov[pixelIndex] = shadowRayPayload.shadowed ? vec3(1.0, 0.0, 0.0) : vec3(0.0, 1.0, 0.0);
                }
#endif
            }
#endif

            // Terminate path if throughput is too small
            if (length(rayPayload.throughput) < 1e-9)
            {
                rayPayload.bitfield |= SHADE_RAY_PAYLOAD_TERMINATE_FLAG;
            }

            // Russian roulette
            if (bounce > rrBounceOffset)
            {
#ifdef RAND_4D
                float k1 = rng4d_next4f(rayPayload.rng_state).x;
#else
                float k1 = rng1d_next1f(rayPayload.rng_state);
#endif

                if (russian_roulette(k1, rayPayload.throughput))
                {
                    rayPayload.bitfield |= SHADE_RAY_PAYLOAD_TERMINATE_FLAG;
                }
            }

            // Handle volume miss
#if MEDIUM_STACK_SIZE > 0
            if ((rayPayload.bitfield & SHADE_RAY_PAYLOAD_VOLUME_WALK_MISS_FLAG) != 0)
            {
#ifdef RAND_4D
                vec2 xi = rng4d_next4f(rayPayload.rng_state).xy;
#else
                vec2 xi = rng1d_next2f(rayPayload.rng_state);
#endif

                float bias = rayPayload.media[mediumIdx - 1].bias;

                sampleVolumeScatteringDirection(xi, bias, rayPayload.ray_dir);

                rayPayload.bitfield &= ~SHADE_RAY_PAYLOAD_VOLUME_WALK_MISS_FLAG;
            }
#endif

            // Update bounce count
            rayPayload.bitfield++;
        }

#if (AOV_MASK & AOV_BIT_DEBUG_BOUNCES) != 0
        uint bounces = (rayPayload.bitfield & SHADE_RAY_PAYLOAD_BOUNCES_MASK);
        BouncesAov[pixelIndex] = colormap_inferno(float(bounces) / float(maxBounces));
#endif

        // Radiance clamping
        vec3 radiance = vec3(rayPayload.radiance);
        float maxValue = max(radiance.r, max(radiance.g, radiance.b));
        if (maxValue > ubo.maxSampleValue)
        {
            radiance *= ubo.maxSampleValue / maxValue;
        }

        vec3 sample_color = max(vec3(0.0), radiance);

        pixel_color += sample_color * invSpp;
    }

#if (AOV_MASK & AOV_BIT_DEBUG_CLOCK_CYCLES) != 0
    int cyclesElapsed = int(clockARB() - start_cycle_count);
    ClockCyclesAov[pixelIndex] = uvec3(cyclesElapsed, 0, 0);
#endif

#if (AOV_MASK & AOV_BIT_COLOR) != 0
    vec3 prevColor = pixel_color;
#ifdef PROGRESSIVE_ACCUMULATION
    if (ubo.sampleOffset > 0)
    {
        prevColor = ColorAov[pixelIndex].rgb;
    }
#endif
    ColorAov[pixelIndex] = vec4(mix(prevColor, pixel_color, ubo.invSampleCount), 1.0);
#endif

#if (AOV_MASK & AOV_BIT_NORMAL) != 0
    vec3 normal = (NormalsAov[pixelIndex] * 2.0) - 1.0;
    NormalsAov[pixelIndex] = (normalize(normal) + 1.0) * 0.5;
#endif
}
